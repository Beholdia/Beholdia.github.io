import{_ as e,c as a,o as i,a as l}from"./app-CeRtq0eM.js";const t={},n=l('<h1 id="加速所有语言模型生成速度的神奇外挂" tabindex="-1"><a class="header-anchor" href="#加速所有语言模型生成速度的神奇外挂"><span>加速所有语言模型生成速度的神奇外挂</span></a></h1><p>[16]</p><h2 id="speculative-decoding" tabindex="-1"><a class="header-anchor" href="#speculative-decoding"><span>speculative decoding</span></a></h2><p>预判语言模型接下来说什么，可以加速所有语言模型生成速度的神奇外挂。而且不需要训练，不需要改动原来的语言模型。</p><h2 id="谁可以担任预言家" tabindex="-1"><a class="header-anchor" href="#谁可以担任预言家"><span>谁可以担任预言家</span></a></h2><ul><li><p>non-autoregressive model。如果让它担任预言家。speculative decoding可以看成是auto 和non-auto的结合。</p></li><li><p>把模型压缩后作为预言家。大模型压缩方式：对参数进行量化，或者对模型做knowledge distillation。总之有很多技术可以把模型变小。但是模型变小后脑子不好使会有错误答案。不过没事。反正最后会看最终语言模型的输出。</p></li><li><p>预言家也可以是搜索引擎。不一定要是语言模型。</p></li><li><p>可以有多个预言家。大家都产生它的预言。谁错了就不用谁了。</p></li></ul>',6),c=[n];function d(s,o){return i(),a("div",null,c)}const r=e(t,[["render",d],["__file","08_speculative_decoding.html.vue"]]),h=JSON.parse('{"path":"/llm/08_speculative_decoding.html","title":"加速所有语言模型生成速度的神奇外挂","lang":"en-US","frontmatter":{},"headers":[{"level":2,"title":"speculative decoding","slug":"speculative-decoding","link":"#speculative-decoding","children":[]},{"level":2,"title":"谁可以担任预言家","slug":"谁可以担任预言家","link":"#谁可以担任预言家","children":[]}],"git":{"updatedTime":null,"contributors":[]},"filePathRelative":"llm/08_speculative_decoding.md"}');export{r as comp,h as data};
