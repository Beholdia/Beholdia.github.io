import{_ as i,r as o,c as l,e as s,w as a,a as t,b as e,o as c,d as n}from"./app-CeRtq0eM.js";const p="/assets/generative_ai-BFPDt81u.png",u="/assets/ar01-Cs0toj3z.png",d="/assets/ar02-DLBFjvcZ.png",g="/assets/nar01-CE0aMTTF.png",m="/assets/arnar01-DmAxFGq5.png",h="/assets/arnar02-BaVBkj6U.png",v="/assets/arnar03-IXFFJmA9.png",_="/assets/arnar04-CIYqRy0u.png",f="/assets/arnar05-BaZTwpnO.png",x="/assets/arnar06-BxM-cIYM.png",A="/assets/arnar07-DspVvyiX.png",R={},b=t('<h1 id="两种生成策略-ar-nar" tabindex="-1"><a class="header-anchor" href="#两种生成策略-ar-nar"><span>两种生成策略： AR &amp; NAR</span></a></h1><p>[15]</p><p><img src="'+p+'" alt="generative ai"></p><p>世界上token 有三万多。<br> 像素更多，由pixel构成。<br> 声音更多，声音由取样点（sample）所构成，每一秒多少取样点由取样解析度构成。</p><p>生成式人工智慧的本质：给一个条件，把基本单位用正确的排序组合起来。</p><p>有两种生成策略：</p><h2 id="自回归模型-autoregressive" tabindex="-1"><a class="header-anchor" href="#自回归模型-autoregressive"><span>自回归模型 autoregressive</span></a></h2><ul><li>对话的AI ：文字接龙，文字接龙的生成方式 autoregressive generation（AR）。在文字上很成功。</li><li>影像呢？ 可以用像素接龙。</li><li>声音可以用sample接龙。</li></ul><p>但事实上，影像和声音不是以autoregressive generation方式生成的。</p><p>这个策略有限制。按部就班、时间较长。 <img src="'+u+'" alt="ar01"><img src="'+d+'" alt="ar02"></p><h2 id="非自回归模型-non-autoregressive" tabindex="-1"><a class="header-anchor" href="#非自回归模型-non-autoregressive"><span>非自回归模型 non-autoregressive</span></a></h2><ul><li>文字也可以non-auto regressive。可以先预测要生成多少字。或者是生成固定长度。</li><li>为什么文字总是用autoregressive呢？因为NAR的品质不好。独立生成时有很多不同想法。multi-modality problem。</li><li>例如NAR会出现“李宏毅是演授”问题。AR不会出现这个问题。</li></ul><p><img src="'+g+'" alt="nar01"></p><h2 id="ar-nar" tabindex="-1"><a class="header-anchor" href="#ar-nar"><span>AR+NAR</span></a></h2><h3 id="从简到繁" tabindex="-1"><a class="header-anchor" href="#从简到繁"><span>从简到繁</span></a></h3><ul><li>精简版本不需要是人可以看懂的。可以拿encoder压缩图片。</li><li>encoder就是一个类神经网络。decoder可以看得懂压缩后的结果，并还原。</li><li>压缩后的图片，压缩程度是16*16 =&gt;1。</li><li>encoder decoder都可以是类神经网络，机器学习训练得到。这个方法叫：auto-encoder 收集一大堆图片，encoder压缩decoder释放，前后越接近越好。用机器学习的方式找出参数(这样就得到了一个压缩和解压工具)。</li><li>autoregressive只要产生压缩版本，丢进decoder，也就是Non-autoregressive的model 解压。</li><li>autoregressive model只要生成比较简单的东西，decoder是一个non-autoregressive的model,可以快速生成。两者取长补短。</li></ul><p><img src="'+m+'" alt="arnar01"></p><p><img src="'+h+'" alt="arnar02"></p>',18),N=t('<h3 id="多次生成non-autoregressive" tabindex="-1"><a class="header-anchor" href="#多次生成non-autoregressive"><span>多次生成non-autoregressive</span></a></h3><p>另外一个克服non-autorefressive的方法就是多次生成non-autoregressive。分成好几个阶段。 多次生成，脑补有限。</p><ul><li>小图到大图</li></ul><p><img src="'+v+'" alt="arnar03"></p><ul><li>有杂讯到无杂讯 有杂讯-&gt;无杂讯的过程：图像生成中鼎鼎大名的diffusion model 。即 生成的过程拆解成生成不同版本的东西，每一个版本比前一个更加清晰。它就是autoregressive和non autoregressive的结合。</li></ul><p><img src="'+_+'" alt="arnar04"></p><ul><li>把不对的地方涂掉</li></ul><p><img src="'+f+'" alt="arnar05"></p><p>那么前面那个autoregressive的生成会不会还是很久呢？ 可以把前面autoregressive的生成直接换成一串non-autoregressive的生成。压缩的第一版-第二版。 也就是一堆non-autoregressive 生成一个人看不懂的压缩，再丢尽decoder生成最后的图片。</p><p><img src="'+x+'" alt="arnar06"></p>',10),k=e("h2",{id:"小结",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#小结"},[e("span",null,"小结")])],-1),B=e("p",null,[e("img",{src:A,alt:"arnar07"})],-1);function F(V,y){const r=o("center");return c(),l("div",null,[b,s(r,null,{default:a(()=>[n("语音也类似。压缩再解压。")]),_:1}),N,s(r,null,{default:a(()=>[n("midjourney：每个压缩后的图都docoder给你看看。")]),_:1}),k,B])}const T=i(R,[["render",F],["__file","07_autoregressive.html.vue"]]),j=JSON.parse('{"path":"/llm/07_autoregressive.html","title":"两种生成策略： AR & NAR","lang":"en-US","frontmatter":{},"headers":[{"level":2,"title":"自回归模型 autoregressive","slug":"自回归模型-autoregressive","link":"#自回归模型-autoregressive","children":[]},{"level":2,"title":"非自回归模型 non-autoregressive","slug":"非自回归模型-non-autoregressive","link":"#非自回归模型-non-autoregressive","children":[]},{"level":2,"title":"AR+NAR","slug":"ar-nar","link":"#ar-nar","children":[{"level":3,"title":"从简到繁","slug":"从简到繁","link":"#从简到繁","children":[]},{"level":3,"title":"多次生成non-autoregressive","slug":"多次生成non-autoregressive","link":"#多次生成non-autoregressive","children":[]}]},{"level":2,"title":"小结","slug":"小结","link":"#小结","children":[]}],"git":{"updatedTime":1753336740000,"contributors":[{"name":"Beholdia","email":"yuanbihe@outlook.com","commits":1}]},"filePathRelative":"llm/07_autoregressive.md"}');export{T as comp,j as data};
