import{_ as s,r as l,c as d,b as e,d as t,e as n,w as o,a,o as m}from"./app-CeRtq0eM.js";const c="/assets/transformer-DOjlR9sK.png",p="/assets/tokenization-CSGbI4NK.png",u="/assets/embedding-BHPx9N1v.png",h="/assets/embedding2-BExVCz4M.png",k="/assets/positional_embedding-CMv205MU.png",g="/assets/attention01-BvDY2R0d.png",b="/assets/attention02-BvoQTSkA.png",_="/assets/attention03-Clik_6hk.png",f="/assets/casual_attention-i398Hls-.png",w="/assets/multi_head_attention-CBebTJHg.png",x="/assets/transformer_block-CZIZwny3.png",v={},y=a('<h1 id="语言模型内部的类神经网络transformer背后做了什么" tabindex="-1"><a class="header-anchor" href="#语言模型内部的类神经网络transformer背后做了什么"><span>语言模型内部的类神经网络transformer背后做了什么？</span></a></h1><p>语言模型是怎么做文字接龙的？[10]</p><h3 id="是什么" tabindex="-1"><a class="header-anchor" href="#是什么"><span>是什么？</span></a></h3><p>语言模型是一个函式，内部有很多未知的参数。可以用训练资料找出这些未知的参数。</p><h3 id="做了什么" tabindex="-1"><a class="header-anchor" href="#做了什么"><span>做了什么？</span></a></h3><p>语言模型做的事情就是文字接龙，文字接龙的能力是从大量的训练资料所学出来的。</p><h3 id="怎么做到的" tabindex="-1"><a class="header-anchor" href="#怎么做到的"><span>怎么做到的？</span></a></h3><p>语言模型背后用的是类神经网络的技术，也就是它背后的函式是一个类神经网络。 语言模型最常用的类神经网络的模型就是transformer。</p><p>语言模型使用的模型的演进：</p><ul><li>N-gram模型(深度学习不发达时)</li><li>Feed-forward Network模型（类神经网络技术）</li><li>Recurrent Neural Network模型（类神经网络技术）</li><li>transformer模型(类神经网络技术)</li></ul><p><img src="'+c+'" alt="transformer"></p><h2 id="第一步-tokenization" tabindex="-1"><a class="header-anchor" href="#第一步-tokenization"><span>第一步 tokenization</span></a></h2><p>把文字转换成token。</p><p>语言模型是以token作为单位对文字进行处理。 语言模型输入和输出的单位都是以token作为单位的。 把一句话给语言模型，它做的第一件事是把这句话转成token的sequence。</p><p><strong>如何转换：</strong></p><p>怎么把一句话转成tokens呢？怎么知道一个语言里面有哪些token呢？我们要先准备一个token列表。一开始在打造语言模型的时候，就会根据对语言的理解，准备一个token列表——也就是语言模型处理文字的基本单位。不同的语言模型，token的列表是不一样的。</p><p><strong>自动取得token：</strong></p><ul><li>有一个演算法叫byte pair encoding (BPE)，可以从大量文字里面找出常常出现的pattern，把这些pattern当作token。</li><li>还有其他找token的方法。</li></ul>',18),z=e("br",null,null,-1),N=e("a",{href:"https://platform.openai.com/tokenizer",target:"_blank",rel:"noopener noreferrer"},"查看openai的token列表",-1),B=a('<p><img src="'+p+'" alt="tokenization"></p><h2 id="第二步-input-layer" tabindex="-1"><a class="header-anchor" href="#第二步-input-layer"><span>第二步 input layer</span></a></h2><p>理解token，知道每一个token是什么意思</p><h3 id="理解token-语意-embedding-token-embedding" tabindex="-1"><a class="header-anchor" href="#理解token-语意-embedding-token-embedding"><span>理解token 语意/embedding/token embedding</span></a></h3>',4),q=a("<li><p>做了什么？<br> 需要把每一个token用一个向量来表示。每一个token丢尽这个模组之后，每一个token变成一串数字，每一个token会变成一个向量。 把token变成向量的<strong>过程</strong>叫做embedding。<br> 我们把每一个token表示成一个向量，有时候直接称呼这些<strong>向量</strong>为embedding。<br> 语言越相近的token，它的embedding距离就越接近。（见下图，比如动物就很接近）<br> 由此，接下来处理的时候就能够知道token和token之间的关联性。</p></li><li><p>怎么做？<br> 怎么把相邻的token给它相近的embedding呢？ 有一个token embedding的列表。 transformer 里有一个table，存了所有的token 跟每一个token所对应的embedding（向量）。 做embedding就是查表。</p></li>",2),C=e("br",null,null,-1),R=e("strong",null,[t("它。"),e("br"),t(" 但是这些embedding有一些限制，就是它")],-1),S=e("br",null,null,-1),V=e("br",null,null,-1),T=e("br",null,null,-1),E=e("p",null,[e("img",{src:u,alt:"embedding"}),e("img",{src:h,alt:"embedding"})],-1),H=e("h3",{id:"理解token-位置-positional-embedding",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#理解token-位置-positional-embedding"},[e("span",null,"理解token 位置/positional embedding")])],-1),M=e("br",null,null,-1),P=e("br",null,null,-1),D=e("br",null,null,-1),I=e("br",null,null,-1),J=e("br",null,null,-1),K=e("img",{src:k,alt:"positional_embedding"},null,-1),O=a('<h2 id="第三步-attention-contextualized-token-embedding" tabindex="-1"><a class="header-anchor" href="#第三步-attention-contextualized-token-embedding"><span>第三步 attention / contextualized token embedding</span></a></h2><p>理解上下文 经过这一模组之后，&quot;苹果电脑&quot;的&quot;果&quot;和&quot;来吃苹果&quot;的&quot;果&quot;的embedding变得不一样了。 这种有考虑上下文的embedding，叫做contextualized token embedding。这个时候同一个token语意不一样。</p><p>attention is all you need发现了不用搭配RNN就有很好的效果。</p><ul><li>attention做了什么 <ul><li>attention做的事情，就是输入一排向量，在这排向量里面每一个向量都代表一个token。它会输出另外一排一样长度的向量。对每一个token来说就是把上下文的资讯，加进它的embedding里面去。具体看一下attention是做了什么事情，使输入的embedding变成输出的embedding。</li><li>计算相关性，再做weighted sum。<br> 从整个句子里找出相关的token，有一个计算相关性的模组，把某一个token的embedding读进去，然后再把句子里的某一个embedding读进去，做一个分数，这个分数代表这两个token之间的关联性，这两个token embedding有多相近，这个分数叫做attention weight。把句子里的全部其他embedding都分别作出attention weight，包括自己本身也要做一个相关性的分数。句子里的每一个向量都要做相关性，再把这些分数加起来。就是输出。 计算相关性的模组也是一个函式。是通过训练资料学到的。</li></ul></li></ul><p><img src="'+g+'" alt="attention01"><img src="'+b+'" alt="attention02"><img src="'+_+'" alt="attention03"></p>',5),U=a('<h3 id="casual-attention" tabindex="-1"><a class="header-anchor" href="#casual-attention"><span>casual attention</span></a></h3><ul><li>但实际上只会考虑每一个token前面的那些token。计算attention weight的时候，只会管它左边的token。这样叫做casual attention。</li><li>为什么呢？<em>再看一下</em></li></ul><p><img src="'+f+'" alt="casual_attention"></p><h3 id="multi-head-attention" tabindex="-1"><a class="header-anchor" href="#multi-head-attention"><span>multi-head attention</span></a></h3><p>attention里面还有一个特别的设计。multi-head attention。 语言模型用的都是multi-head attention。 相关性不止一种。例如 dog cat ,dog bark。所以需要多个计算关联性的模组。不同的计算关联性的模组，都有自己的参数，这些参数都是透过训练资料学出来的。它们会算出不同的attention weight。</p><p>然后根据每一组attention weight 做weighted sum。所以实际上attention mudual<strong>不止一组输出</strong>。根据每一种关联性都会给我们一组输出。我们要把这些输出整合起来，我们要用到另一个模组，叫做feed forward network。</p><p><img src="'+w+'" alt="multi_head_attention"></p><h2 id="第四步-feed-forward" tabindex="-1"><a class="header-anchor" href="#第四步-feed-forward"><span>第四步 feed forward</span></a></h2><p>feed forward network会把多组输出综合考虑一下，最终给出一个向量。</p><p>feedforward模组也是一个neural network。里面也有很多层很多参数。参数也是透过训练资料学习出来的。 attention的模组加上feed forward的模组组合起来，就是一个transformer的block。是transformer内的基本单位。</p><p><img src="'+x+'" alt="transformer_block"></p><h2 id="第三四步多次-transformer-block" tabindex="-1"><a class="header-anchor" href="#第三四步多次-transformer-block"><span>第三四步多次 transformer block</span></a></h2><ul><li>一个transformer里面，有多个transformer block。</li><li>总结：一开始，我们通过第一个模组做tokenization，第二个模组是token embedding，得到第一组的token embedding后，就会通过transformer的block，里面有attention，有 feedforward network，你会得到另外一组embedding，这组embedding是考虑过上下文的embedding。</li><li>光通过一个transformer block是不够的，会把它再通过下一个transformer block，好几次。每一个transformer block会称为一个layer（虽然实际上如果从neural network的角度看，一个transformer block里面，也已经有很多层的neural network ）。所以，输入的embedding，会通过多个transformer block ，一直到通过最后一个transformer block之后，把句尾的这一个向量拿出来，再把句尾的向量，通过一个output layer。</li></ul><h2 id="第五步-output-layer" tabindex="-1"><a class="header-anchor" href="#第五步-output-layer"><span>第五步 output layer</span></a></h2><ul><li>output layer也是一个function，output layer里面有一个linear transform ，有一个softmax。然后会得到一个几率的分布。 就是说，transformer block最后一层的最后一个输出，丢给另外一个模组，这个模组，会输出一个机率分布给我们。</li></ul><p>一个句子从输入到transformer，一直到最终输出一个机率分布，代表了下一个token，应该接哪一个token的几率。</p><h2 id="为什么处理超长文本会是挑战" tabindex="-1"><a class="header-anchor" href="#为什么处理超长文本会是挑战"><span>为什么处理超长文本会是挑战</span></a></h2><p>如果输入100k，对语言模型来说，100k个token需要两两之间计算attention。计算attention weight的次数和文本token长度的平方成正比。 研究方向……</p>',18);function Z(j,A){const i=l("font"),r=l("center");return m(),d("div",null,[y,e("p",null,[t("这部分没有要训练的参数，是一个人事先定好的module。"),n(i,{color:"red"},{default:o(()=>[t("人为设定")]),_:1}),z,t(" 每个语言模型用的token都是不一样的。 "),N,t("。")]),B,e("ul",null,[q,e("li",null,[e("p",null,[t("哪里来？"),C,t(" 这个表是从哪里来的呢？怎么知道每一个token对应的向量是什么呢？token所对应的向量就是语言模型里面的参数，就是通过大量训练资料找的参数的一部分。 token的embedding"),n(i,{color:"red"},{default:o(()=>[t("不需要人设定")]),_:1}),R,t("没有考虑上下文**。同一个token它的embedding就是固定的。"),S,t(" bank不管表示哪一个意思，它的embedding都是一样的。"),V,t(" 第三阶段才考虑上下文。"),T])])]),E,H,e("p",null,[t("上面考虑了语意的资讯，其实还需要考虑位置的资讯。我们需要知道每一个token是在句子里的哪一个位置。"),M,t(" 因为同一个token，在句子里面不同位置，可能会代表不同的意思。"),P,t(" 怎么把位置的资讯加到token的embedding里面去呢？一个可能的做法是为每一个位置也设定一个向量：positional embedding。"),D,t(" 那么一个token除了表示语义的embedding之后，还要再加上表示位置的embedding。"),I,t(" positional embedding可以"),n(i,{color:"red"},{default:o(()=>[t("人设计")]),_:1}),t("，也可以"),n(i,{color:"red"},{default:o(()=>[t("训练得到")]),_:1}),t("：作为参数的一部分。"),J,K]),O,n(r,null,{default:o(()=>[t("如果有5个向量，就会有25个attention weight。")]),_:1}),U])}const G=s(v,[["render",Z],["__file","04_transformer.html.vue"]]),Q=JSON.parse('{"path":"/llm/04_transformer.html","title":"语言模型内部的类神经网络transformer背后做了什么？","lang":"en-US","frontmatter":{},"headers":[{"level":3,"title":"是什么？","slug":"是什么","link":"#是什么","children":[]},{"level":3,"title":"做了什么？","slug":"做了什么","link":"#做了什么","children":[]},{"level":3,"title":"怎么做到的？","slug":"怎么做到的","link":"#怎么做到的","children":[]},{"level":2,"title":"第一步 tokenization","slug":"第一步-tokenization","link":"#第一步-tokenization","children":[]},{"level":2,"title":"第二步 input layer","slug":"第二步-input-layer","link":"#第二步-input-layer","children":[{"level":3,"title":"理解token 语意/embedding/token embedding","slug":"理解token-语意-embedding-token-embedding","link":"#理解token-语意-embedding-token-embedding","children":[]},{"level":3,"title":"理解token 位置/positional embedding","slug":"理解token-位置-positional-embedding","link":"#理解token-位置-positional-embedding","children":[]}]},{"level":2,"title":"第三步 attention / contextualized token embedding","slug":"第三步-attention-contextualized-token-embedding","link":"#第三步-attention-contextualized-token-embedding","children":[{"level":3,"title":"casual attention","slug":"casual-attention","link":"#casual-attention","children":[]},{"level":3,"title":"multi-head attention","slug":"multi-head-attention","link":"#multi-head-attention","children":[]}]},{"level":2,"title":"第四步 feed forward","slug":"第四步-feed-forward","link":"#第四步-feed-forward","children":[]},{"level":2,"title":"第三四步多次 transformer block","slug":"第三四步多次-transformer-block","link":"#第三四步多次-transformer-block","children":[]},{"level":2,"title":"第五步 output layer","slug":"第五步-output-layer","link":"#第五步-output-layer","children":[]},{"level":2,"title":"为什么处理超长文本会是挑战","slug":"为什么处理超长文本会是挑战","link":"#为什么处理超长文本会是挑战","children":[]}],"git":{"updatedTime":1753336740000,"contributors":[{"name":"Beholdia","email":"yuanbihe@outlook.com","commits":2}]},"filePathRelative":"llm/04_transformer.md"}');export{G as comp,Q as data};
